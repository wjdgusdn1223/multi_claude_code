#!/usr/bin/env python3
"""
Intelligent Review and Approval System for Multi-Agent Claude Code
ì§€ëŠ¥ì  ë¦¬ë·° ë° ìŠ¹ì¸ ì‹œìŠ¤í…œ - AI ê°„ ë§¤ìš° ì´ì„±ì ì´ê³  ì—„ê²©í•œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤
"""

import os
import json
import yaml
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum
from dataclasses import dataclass, asdict
import hashlib
import re

class ReviewType(Enum):
    TECHNICAL_REVIEW = "technical_review"
    BUSINESS_REVIEW = "business_review"
    QUALITY_REVIEW = "quality_review"
    SECURITY_REVIEW = "security_review"
    ARCHITECTURE_REVIEW = "architecture_review"
    CODE_REVIEW = "code_review"
    DESIGN_REVIEW = "design_review"
    FINAL_APPROVAL = "final_approval"

class ReviewStatus(Enum):
    PENDING = "pending"
    IN_REVIEW = "in_review"
    APPROVED = "approved"
    REJECTED = "rejected"
    NEEDS_REVISION = "needs_revision"
    CONDITIONAL_APPROVAL = "conditional_approval"

class CriticalityLevel(Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"

@dataclass
class ReviewCriterion:
    """ë¦¬ë·° ê¸°ì¤€"""
    criterion_id: str
    name: str
    description: str
    weight: float  # ê°€ì¤‘ì¹˜ (0.0 - 1.0)
    mandatory: bool
    validation_rules: List[str]
    evaluation_method: str

@dataclass
class ReviewIssue:
    """ë¦¬ë·° ì´ìŠˆ"""
    issue_id: str
    criterion_id: str
    severity: CriticalityLevel
    title: str
    description: str
    location: str  # íŒŒì¼ ê²½ë¡œë‚˜ ì„¹ì…˜
    suggested_fix: str
    blocking: bool  # ìŠ¹ì¸ì„ ë§‰ëŠ” ì´ìŠˆì¸ì§€
    evidence: List[str]

@dataclass
class ReviewResult:
    """ë¦¬ë·° ê²°ê³¼"""
    review_id: str
    reviewer_role: str
    reviewee_role: str
    deliverable_path: str
    review_type: ReviewType
    status: ReviewStatus
    overall_score: float  # 0.0 - 1.0
    created_at: datetime
    completed_at: Optional[datetime]
    issues: List[ReviewIssue]
    recommendations: List[str]
    decision_rationale: str
    revision_required: bool
    next_reviewer: Optional[str]

class IntelligentReviewEngine:
    """ì§€ëŠ¥ì  ë¦¬ë·° ì—”ì§„"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.reviews_dir = self.project_root / "reviews"
        self.criteria_dir = self.project_root / "review_criteria"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.reviews_dir.mkdir(exist_ok=True)
        self.criteria_dir.mkdir(exist_ok=True)
        
        # ë¦¬ë·° ê¸°ì¤€ ì´ˆê¸°í™”
        self.review_criteria = self._initialize_review_criteria()
        self.active_reviews: Dict[str, ReviewResult] = {}
        
        # ì—­í• ë³„ ë¦¬ë·° ê¶Œí•œ ë§¤í•‘
        self.reviewer_capabilities = self._initialize_reviewer_capabilities()
        
        print("ğŸ” Intelligent Review System ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_review_criteria(self) -> Dict[str, List[ReviewCriterion]]:
        """ë¦¬ë·° ê¸°ì¤€ ì´ˆê¸°í™”"""
        criteria = {}
        
        # ê¸°ìˆ  ë¦¬ë·° ê¸°ì¤€
        criteria[ReviewType.TECHNICAL_REVIEW.value] = [
            ReviewCriterion(
                criterion_id="tech_accuracy",
                name="ê¸°ìˆ ì  ì •í™•ì„±",
                description="ê¸°ìˆ ì  ë‚´ìš©ì˜ ì •í™•ì„±ê³¼ ì‹¤í˜„ ê°€ëŠ¥ì„±",
                weight=0.3,
                mandatory=True,
                validation_rules=[
                    "ê¸°ìˆ  ìŠ¤íƒ í˜¸í™˜ì„± í™•ì¸",
                    "API ëª…ì„¸ ì •í™•ì„± ê²€ì¦",
                    "ë°ì´í„° ëª¨ë¸ ì¼ê´€ì„± í™•ì¸",
                    "ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ë‹¬ì„± ê°€ëŠ¥ì„±"
                ],
                evaluation_method="technical_analysis"
            ),
            ReviewCriterion(
                criterion_id="implementation_feasibility",
                name="êµ¬í˜„ ê°€ëŠ¥ì„±",
                description="ì œì•ˆëœ ì†”ë£¨ì…˜ì˜ ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥ì„±",
                weight=0.25,
                mandatory=True,
                validation_rules=[
                    "ê¸°ìˆ ì  ë³µì¡ë„ ì ì ˆì„±",
                    "ê°œë°œ ì‹œê°„ í˜„ì‹¤ì„±",
                    "ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ í•©ë¦¬ì„±",
                    "ì˜ì¡´ì„± ê´€ë¦¬ ì ì ˆì„±"
                ],
                evaluation_method="feasibility_analysis"
            ),
            ReviewCriterion(
                criterion_id="scalability",
                name="í™•ì¥ì„±",
                description="ì‹œìŠ¤í…œì˜ í™•ì¥ ê°€ëŠ¥ì„±ê³¼ ìœ ì—°ì„±",
                weight=0.2,
                mandatory=False,
                validation_rules=[
                    "ë¶€í•˜ ì¦ê°€ ëŒ€ì‘ ëŠ¥ë ¥",
                    "ê¸°ëŠ¥ í™•ì¥ ìš©ì´ì„±",
                    "ì•„í‚¤í…ì²˜ ìœ ì—°ì„±"
                ],
                evaluation_method="scalability_assessment"
            ),
            ReviewCriterion(
                criterion_id="security_compliance",
                name="ë³´ì•ˆ ì¤€ìˆ˜",
                description="ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ ì¤€ìˆ˜ ì—¬ë¶€",
                weight=0.25,
                mandatory=True,
                validation_rules=[
                    "ì¸ì¦/ì¸ê°€ ì²´ê³„ ì ì ˆì„±",
                    "ë°ì´í„° ì•”í˜¸í™” ë°©ì•ˆ",
                    "ë³´ì•ˆ ì·¨ì•½ì  ê²€í† ",
                    "ê°œì¸ì •ë³´ ë³´í˜¸ ì¤€ìˆ˜"
                ],
                evaluation_method="security_review"
            )
        ]
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ë·° ê¸°ì¤€
        criteria[ReviewType.BUSINESS_REVIEW.value] = [
            ReviewCriterion(
                criterion_id="business_value",
                name="ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜",
                description="ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì™€ì˜ ì¼ì¹˜ì„±",
                weight=0.4,
                mandatory=True,
                validation_rules=[
                    "ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ ë‹¬ì„± ê¸°ì—¬ë„",
                    "ROI ì •ë‹¹ì„±",
                    "ì‚¬ìš©ì ê°€ì¹˜ ì°½ì¶œ",
                    "ê²½ìŸ ìš°ìœ„ í™•ë³´"
                ],
                evaluation_method="business_analysis"
            ),
            ReviewCriterion(
                criterion_id="requirement_completeness",
                name="ìš”êµ¬ì‚¬í•­ ì™„ì „ì„±",
                description="ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì˜ ì™„ì „ì„±ê³¼ ëª…í™•ì„±",
                weight=0.3,
                mandatory=True,
                validation_rules=[
                    "ëª¨ë“  ì´í•´ê´€ê³„ì ìš”êµ¬ì‚¬í•­ ë°˜ì˜",
                    "ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­ ì™„ì „ì„±",
                    "ë¹„ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­ ëª…í™•ì„±",
                    "ì œì•½ì‚¬í•­ ì‹ë³„ ì™„ë£Œ"
                ],
                evaluation_method="completeness_check"
            ),
            ReviewCriterion(
                criterion_id="user_experience",
                name="ì‚¬ìš©ì ê²½í—˜",
                description="ìµœì¢… ì‚¬ìš©ì ê´€ì ì—ì„œì˜ ê²½í—˜ í’ˆì§ˆ",
                weight=0.2,
                mandatory=False,
                validation_rules=[
                    "ì‚¬ìš©ì„± ê³ ë ¤",
                    "ì ‘ê·¼ì„± ì¤€ìˆ˜",
                    "ì‚¬ìš©ì ì—¬ì • ìµœì í™”"
                ],
                evaluation_method="ux_evaluation"
            ),
            ReviewCriterion(
                criterion_id="risk_assessment",
                name="ë¦¬ìŠ¤í¬ í‰ê°€",
                description="ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬ ì‹ë³„ ë° ëŒ€ì‘ë°©ì•ˆ",
                weight=0.1,
                mandatory=False,
                validation_rules=[
                    "ì£¼ìš” ë¦¬ìŠ¤í¬ ì‹ë³„",
                    "ë¦¬ìŠ¤í¬ ëŒ€ì‘ë°©ì•ˆ ìˆ˜ë¦½",
                    "ë¦¬ìŠ¤í¬ ì˜í–¥ë„ í‰ê°€"
                ],
                evaluation_method="risk_analysis"
            )
        ]
        
        # í’ˆì§ˆ ë¦¬ë·° ê¸°ì¤€
        criteria[ReviewType.QUALITY_REVIEW.value] = [
            ReviewCriterion(
                criterion_id="documentation_quality",
                name="ë¬¸ì„œí™” í’ˆì§ˆ",
                description="ë¬¸ì„œì˜ ëª…í™•ì„±, ì™„ì „ì„±, ì¼ê´€ì„±",
                weight=0.25,
                mandatory=True,
                validation_rules=[
                    "ë‚´ìš© ëª…í™•ì„±",
                    "êµ¬ì¡° ì¼ê´€ì„±",
                    "ì •ë³´ ì™„ì „ì„±",
                    "ê°€ë…ì„±"
                ],
                evaluation_method="documentation_analysis"
            ),
            ReviewCriterion(
                criterion_id="consistency",
                name="ì¼ê´€ì„±",
                description="í”„ë¡œì íŠ¸ ì „ì²´ì™€ì˜ ì¼ê´€ì„±",
                weight=0.25,
                mandatory=True,
                validation_rules=[
                    "ëª…ëª… ê·œì¹™ ì¼ê´€ì„±",
                    "ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¤€ìˆ˜",
                    "ë‹¤ë¥¸ ë¬¸ì„œì™€ì˜ ì¼ì¹˜ì„±",
                    "ìš©ì–´ ì‚¬ìš© ì¼ê´€ì„±"
                ],
                evaluation_method="consistency_check"
            ),
            ReviewCriterion(
                criterion_id="testability",
                name="í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±",
                description="í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ëª…ì„¸ë˜ì—ˆëŠ”ì§€",
                weight=0.25,
                mandatory=True,
                validation_rules=[
                    "í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë„ì¶œ ê°€ëŠ¥ì„±",
                    "ê²€ì¦ ê¸°ì¤€ ëª…í™•ì„±",
                    "ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³µ ê¸°ì¤€"
                ],
                evaluation_method="testability_assessment"
            ),
            ReviewCriterion(
                criterion_id="maintainability",
                name="ìœ ì§€ë³´ìˆ˜ì„±",
                description="í–¥í›„ ìœ ì§€ë³´ìˆ˜ì˜ ìš©ì´ì„±",
                weight=0.25,
                mandatory=False,
                validation_rules=[
                    "ì½”ë“œ ê°€ë…ì„±",
                    "ëª¨ë“ˆí™” ìˆ˜ì¤€",
                    "ë¬¸ì„œí™” ìˆ˜ì¤€",
                    "ë³€ê²½ ì˜í–¥ë„ ìµœì†Œí™”"
                ],
                evaluation_method="maintainability_check"
            )
        ]
        
        return criteria
    
    def _initialize_reviewer_capabilities(self) -> Dict[str, List[ReviewType]]:
        """ì—­í• ë³„ ë¦¬ë·° ëŠ¥ë ¥ ë§¤í•‘"""
        return {
            "technical_reviewer": [
                ReviewType.TECHNICAL_REVIEW,
                ReviewType.QUALITY_REVIEW,
                ReviewType.CODE_REVIEW
            ],
            "senior_developer": [
                ReviewType.TECHNICAL_REVIEW,
                ReviewType.ARCHITECTURE_REVIEW,
                ReviewType.CODE_REVIEW
            ],
            "system_architect": [
                ReviewType.ARCHITECTURE_REVIEW,
                ReviewType.TECHNICAL_REVIEW
            ],
            "product_owner": [
                ReviewType.BUSINESS_REVIEW,
                ReviewType.FINAL_APPROVAL
            ],
            "business_analyst": [
                ReviewType.BUSINESS_REVIEW,
                ReviewType.QUALITY_REVIEW
            ],
            "security_tester": [
                ReviewType.SECURITY_REVIEW
            ],
            "qa_tester": [
                ReviewType.QUALITY_REVIEW
            ],
            "project_manager": [
                ReviewType.FINAL_APPROVAL
            ]
        }
    
    def request_review(self, 
                      deliverable_path: str,
                      reviewee_role: str,
                      review_type: ReviewType,
                      priority: CriticalityLevel = CriticalityLevel.MEDIUM,
                      custom_criteria: List[str] = None) -> str:
        """ë¦¬ë·° ìš”ì²­"""
        
        # ì ì ˆí•œ ë¦¬ë·°ì–´ ì‹ë³„
        reviewer_role = self._identify_best_reviewer(review_type, reviewee_role)
        
        if not reviewer_role:
            raise ValueError(f"ì ì ˆí•œ ë¦¬ë·°ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {review_type}")
        
        # ë¦¬ë·° ID ìƒì„±
        review_id = f"{review_type.value}_{reviewee_role}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ë¦¬ë·° ê²°ê³¼ ê°ì²´ ìƒì„±
        review_result = ReviewResult(
            review_id=review_id,
            reviewer_role=reviewer_role,
            reviewee_role=reviewee_role,
            deliverable_path=deliverable_path,
            review_type=review_type,
            status=ReviewStatus.PENDING,
            overall_score=0.0,
            created_at=datetime.now(),
            completed_at=None,
            issues=[],
            recommendations=[],
            decision_rationale="",
            revision_required=False,
            next_reviewer=None
        )
        
        # ë¦¬ë·° ì €ì¥
        self.active_reviews[review_id] = review_result
        self._save_review_result(review_result)
        
        # ë¦¬ë·°ì–´ì—ê²Œ ë¦¬ë·° ìš”ì²­ ë©”ì‹œì§€ ì „ì†¡
        self._send_review_request(review_result, custom_criteria)
        
        print(f"ğŸ“‹ ë¦¬ë·° ìš”ì²­: {deliverable_path} ({review_type.value}) -> {reviewer_role}")
        return review_id
    
    def conduct_intelligent_review(self, review_id: str) -> ReviewResult:
        """ì§€ëŠ¥ì  ë¦¬ë·° ìˆ˜í–‰"""
        
        review_result = self.active_reviews.get(review_id)
        if not review_result:
            raise ValueError(f"ë¦¬ë·°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {review_id}")
        
        print(f"ğŸ” ì§€ëŠ¥ì  ë¦¬ë·° ì‹œì‘: {review_id}")
        
        # ë¦¬ë·° ìƒíƒœ ì—…ë°ì´íŠ¸
        review_result.status = ReviewStatus.IN_REVIEW
        
        # ì‚°ì¶œë¬¼ ë¶„ì„
        deliverable_content = self._load_deliverable(review_result.deliverable_path)
        
        # ë¦¬ë·° ê¸°ì¤€ ì ìš©
        criteria_list = self.review_criteria.get(review_result.review_type.value, [])
        
        total_score = 0.0
        total_weight = 0.0
        all_issues = []
        recommendations = []
        
        for criterion in criteria_list:
            # ê° ê¸°ì¤€ë³„ í‰ê°€
            score, issues, recs = self._evaluate_criterion(
                criterion, 
                deliverable_content, 
                review_result
            )
            
            total_score += score * criterion.weight
            total_weight += criterion.weight
            all_issues.extend(issues)
            recommendations.extend(recs)
            
            print(f"  ğŸ“Š {criterion.name}: {score:.2f}")
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = total_score / total_weight if total_weight > 0 else 0.0
        
        # ë¦¬ë·° ê²°ê³¼ ì—…ë°ì´íŠ¸
        review_result.overall_score = overall_score
        review_result.issues = all_issues
        review_result.recommendations = recommendations
        review_result.completed_at = datetime.now()
        
        # ìŠ¹ì¸/ê±°ë¶€ ê²°ì •
        decision = self._make_approval_decision(review_result)
        review_result.status = decision['status']
        review_result.decision_rationale = decision['rationale']
        review_result.revision_required = decision['revision_required']
        review_result.next_reviewer = decision.get('next_reviewer')
        
        # ê²°ê³¼ ì €ì¥
        self._save_review_result(review_result)
        
        # ë¦¬ë·° ê²°ê³¼ í†µì§€
        self._notify_review_completion(review_result)
        
        print(f"âœ… ë¦¬ë·° ì™„ë£Œ: {review_id} - {review_result.status.value} (ì ìˆ˜: {overall_score:.2f})")
        
        return review_result
    
    def _identify_best_reviewer(self, review_type: ReviewType, reviewee_role: str) -> Optional[str]:
        """ìµœì  ë¦¬ë·°ì–´ ì‹ë³„"""
        
        # ë¦¬ë·° íƒ€ì…ë³„ ì ì ˆí•œ ë¦¬ë·°ì–´ ì°¾ê¸°
        candidate_reviewers = []
        
        for role, capabilities in self.reviewer_capabilities.items():
            if review_type in capabilities and role != reviewee_role:
                candidate_reviewers.append(role)
        
        if not candidate_reviewers:
            return None
        
        # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì„ íƒ
        priority_map = {
            ReviewType.TECHNICAL_REVIEW: ["senior_developer", "technical_reviewer", "system_architect"],
            ReviewType.BUSINESS_REVIEW: ["product_owner", "business_analyst"],
            ReviewType.ARCHITECTURE_REVIEW: ["system_architect", "senior_developer"],
            ReviewType.SECURITY_REVIEW: ["security_tester"],
            ReviewType.QUALITY_REVIEW: ["qa_tester", "technical_reviewer"],
            ReviewType.FINAL_APPROVAL: ["project_manager", "product_owner"]
        }
        
        preferred_order = priority_map.get(review_type, candidate_reviewers)
        
        for preferred_reviewer in preferred_order:
            if preferred_reviewer in candidate_reviewers:
                return preferred_reviewer
        
        return candidate_reviewers[0] if candidate_reviewers else None
    
    def _load_deliverable(self, deliverable_path: str) -> Dict[str, Any]:
        """ì‚°ì¶œë¬¼ ë¡œë“œ ë° ë¶„ì„"""
        
        full_path = self.project_root / deliverable_path
        
        if not full_path.exists():
            return {"error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ", "path": deliverable_path}
        
        try:
            # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì²˜ë¦¬
            if full_path.suffix.lower() in ['.md', '.txt']:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                return {
                    "file_type": "text",
                    "content": content,
                    "line_count": len(content.splitlines()),
                    "word_count": len(content.split()),
                    "char_count": len(content),
                    "sections": self._extract_markdown_sections(content)
                }
            
            elif full_path.suffix.lower() in ['.json']:
                with open(full_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                return {
                    "file_type": "json",
                    "content": data,
                    "structure": self._analyze_json_structure(data)
                }
            
            elif full_path.suffix.lower() in ['.yaml', '.yml']:
                with open(full_path, 'r', encoding='utf-8') as f:
                    data = yaml.safe_load(f)
                
                return {
                    "file_type": "yaml",
                    "content": data,
                    "structure": self._analyze_yaml_structure(data)
                }
            
            else:
                return {"error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹", "file_type": full_path.suffix}
        
        except Exception as e:
            return {"error": f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"}
    
    def _evaluate_criterion(self, 
                          criterion: ReviewCriterion, 
                          deliverable_content: Dict[str, Any], 
                          review_result: ReviewResult) -> Tuple[float, List[ReviewIssue], List[str]]:
        """ê¸°ì¤€ë³„ í‰ê°€"""
        
        if criterion.evaluation_method == "technical_analysis":
            return self._evaluate_technical_accuracy(criterion, deliverable_content, review_result)
        elif criterion.evaluation_method == "feasibility_analysis":
            return self._evaluate_implementation_feasibility(criterion, deliverable_content, review_result)
        elif criterion.evaluation_method == "business_analysis":
            return self._evaluate_business_value(criterion, deliverable_content, review_result)
        elif criterion.evaluation_method == "documentation_analysis":
            return self._evaluate_documentation_quality(criterion, deliverable_content, review_result)
        elif criterion.evaluation_method == "consistency_check":
            return self._evaluate_consistency(criterion, deliverable_content, review_result)
        else:
            return self._evaluate_generic_criterion(criterion, deliverable_content, review_result)
    
    def _evaluate_technical_accuracy(self, 
                                   criterion: ReviewCriterion, 
                                   content: Dict[str, Any], 
                                   review_result: ReviewResult) -> Tuple[float, List[ReviewIssue], List[str]]:
        """ê¸°ìˆ ì  ì •í™•ì„± í‰ê°€"""
        
        issues = []
        recommendations = []
        score = 1.0  # ê¸°ë³¸ ë§Œì ì—ì„œ ì‹œì‘
        
        if content.get("error"):
            issues.append(ReviewIssue(
                issue_id=f"tech_acc_001_{datetime.now().strftime('%H%M%S')}",
                criterion_id=criterion.criterion_id,
                severity=CriticalityLevel.CRITICAL,
                title="íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜",
                description=content["error"],
                location=review_result.deliverable_path,
                suggested_fix="íŒŒì¼ í˜•ì‹ê³¼ ì¸ì½”ë”©ì„ í™•ì¸í•˜ì„¸ìš”",
                blocking=True,
                evidence=[]
            ))
            return 0.0, issues, recommendations
        
        # ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œì¸ ê²½ìš°
        if content.get("file_type") == "text":
            text_content = content.get("content", "")
            
            # ê¸°ìˆ  ìš©ì–´ ì¼ê´€ì„± í™•ì¸
            tech_terms = ["API", "REST", "HTTP", "JSON", "JWT", "PostgreSQL", "React", "Node.js"]
            inconsistent_terms = self._check_technical_term_consistency(text_content, tech_terms)
            
            for term_issue in inconsistent_terms:
                issues.append(ReviewIssue(
                    issue_id=f"tech_acc_002_{len(issues)}",
                    criterion_id=criterion.criterion_id,
                    severity=CriticalityLevel.MEDIUM,
                    title=f"ê¸°ìˆ  ìš©ì–´ ë¶ˆì¼ì¹˜: {term_issue['term']}",
                    description=f"ê¸°ìˆ  ìš©ì–´ '{term_issue['term']}'ì´ ì¼ê´€ë˜ì§€ ì•Šê²Œ ì‚¬ìš©ë¨",
                    location=f"ë¼ì¸ {term_issue['lines']}",
                    suggested_fix=f"'{term_issue['standard_form']}'ìœ¼ë¡œ í†µì¼ ì‚¬ìš©",
                    blocking=False,
                    evidence=term_issue['examples']
                ))
                score -= 0.1
            
            # API ëª…ì„¸ ê²€ì¦
            if "api" in text_content.lower() or "endpoint" in text_content.lower():
                api_issues = self._validate_api_specifications(text_content)
                issues.extend(api_issues)
                score -= len(api_issues) * 0.15
            
            # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ê²€ì¦
            if any(word in text_content.lower() for word in ["database", "table", "schema", "sql"]):
                db_issues = self._validate_database_specifications(text_content)
                issues.extend(db_issues)
                score -= len(db_issues) * 0.15
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if score < 0.8:
            recommendations.extend([
                "ê¸°ìˆ  ëª…ì„¸ì˜ ì •í™•ì„±ì„ ë†’ì´ê¸° ìœ„í•´ í‘œì¤€ ìš©ì–´ì§‘ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤",
                "API ëª…ì„¸ëŠ” OpenAPI 3.0 í‘œì¤€ì„ ì¤€ìˆ˜í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤",
                "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆëŠ” ì •ê·œí™” ì›ì¹™ì„ ì¤€ìˆ˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”"
            ])
        
        return max(0.0, score), issues, recommendations
    
    def _evaluate_implementation_feasibility(self, 
                                           criterion: ReviewCriterion, 
                                           content: Dict[str, Any], 
                                           review_result: ReviewResult) -> Tuple[float, List[ReviewIssue], List[str]]:
        """êµ¬í˜„ ê°€ëŠ¥ì„± í‰ê°€"""
        
        issues = []
        recommendations = []
        score = 1.0
        
        if content.get("file_type") == "text":
            text_content = content.get("content", "")
            
            # ë³µì¡ë„ ë¶„ì„
            complexity_indicators = [
                "real-time", "ì‹¤ì‹œê°„", "high-performance", "ê³ ì„±ëŠ¥",
                "machine learning", "AI", "blockchain", "microservices"
            ]
            
            high_complexity_count = sum(1 for indicator in complexity_indicators 
                                      if indicator.lower() in text_content.lower())
            
            if high_complexity_count > 3:
                issues.append(ReviewIssue(
                    issue_id=f"impl_feas_001",
                    criterion_id=criterion.criterion_id,
                    severity=CriticalityLevel.HIGH,
                    title="êµ¬í˜„ ë³µì¡ë„ ë†’ìŒ",
                    description=f"ê³ ë³µì¡ë„ ìš”ì†Œ {high_complexity_count}ê°œ ê°ì§€",
                    location="ì „ì²´ ë¬¸ì„œ",
                    suggested_fix="ë³µì¡ë„ë¥¼ ë‚®ì¶”ê±°ë‚˜ ë‹¨ê³„ì  êµ¬í˜„ ê³„íš ìˆ˜ë¦½",
                    blocking=False,
                    evidence=[f"ë³µì¡ë„ ì§€í‘œ: {high_complexity_count}ê°œ"]
                ))
                score -= 0.3
            
            # ì‹œê°„ ì œì•½ ë¶„ì„
            if "7ì¼" in text_content or "1ì£¼" in text_content:
                word_count = content.get("word_count", 0)
                if word_count > 10000:  # ë§¤ìš° ê¸´ ëª…ì„¸ì„œ
                    issues.append(ReviewIssue(
                        issue_id=f"impl_feas_002",
                        criterion_id=criterion.criterion_id,
                        severity=CriticalityLevel.HIGH,
                        title="ì‹œê°„ ëŒ€ë¹„ ë²”ìœ„ ê³¼ë‹¤",
                        description="7ì¼ ì¼ì • ëŒ€ë¹„ ëª…ì„¸ ë²”ìœ„ê°€ ê³¼ë„í•¨",
                        location="ì „ì²´ ë¬¸ì„œ",
                        suggested_fix="í•µì‹¬ ê¸°ëŠ¥ ìœ„ì£¼ë¡œ ë²”ìœ„ ì¶•ì†Œ í•„ìš”",
                        blocking=True,
                        evidence=[f"ë¬¸ì„œ ê¸¸ì´: {word_count} ë‹¨ì–´"]
                    ))
                    score -= 0.4
        
        return max(0.0, score), issues, recommendations
    
    def _evaluate_business_value(self, 
                               criterion: ReviewCriterion, 
                               content: Dict[str, Any], 
                               review_result: ReviewResult) -> Tuple[float, List[ReviewIssue], List[str]]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ í‰ê°€"""
        
        issues = []
        recommendations = []
        score = 1.0
        
        if content.get("file_type") == "text":
            text_content = content.get("content", "")
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ í‚¤ì›Œë“œ í™•ì¸
            business_value_keywords = [
                "ì‚¬ìš©ì", "ê³ ê°", "íš¨ìœ¨ì„±", "ìƒì‚°ì„±", "ROI", "ìˆ˜ìµ",
                "ë¹„ìš© ì ˆê°", "ê²½ìŸë ¥", "ë§Œì¡±ë„", "ê°€ì¹˜"
            ]
            
            value_mentions = sum(1 for keyword in business_value_keywords 
                               if keyword in text_content)
            
            if value_mentions < 3:
                issues.append(ReviewIssue(
                    issue_id=f"biz_val_001",
                    criterion_id=criterion.criterion_id,
                    severity=CriticalityLevel.MEDIUM,
                    title="ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì–¸ê¸‰ ë¶€ì¡±",
                    description="ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ì— ëŒ€í•œ ëª…í™•í•œ ì–¸ê¸‰ì´ ë¶€ì¡±í•¨",
                    location="ì „ì²´ ë¬¸ì„œ",
                    suggested_fix="êµ¬ì²´ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ì™€ ì¸¡ì • ì§€í‘œ ì¶”ê°€",
                    blocking=False,
                    evidence=[f"ê°€ì¹˜ ê´€ë ¨ ì–¸ê¸‰: {value_mentions}íšŒ"]
                ))
                score -= 0.3
            
            # ì‚¬ìš©ì ì¤‘ì‹¬ì„± í™•ì¸
            user_focus_keywords = ["ì‚¬ìš©ì", "ê³ ê°", "user", "customer"]
            user_mentions = sum(text_content.lower().count(keyword.lower()) 
                              for keyword in user_focus_keywords)
            
            if user_mentions < 5:
                issues.append(ReviewIssue(
                    issue_id=f"biz_val_002",
                    criterion_id=criterion.criterion_id,
                    severity=CriticalityLevel.MEDIUM,
                    title="ì‚¬ìš©ì ì¤‘ì‹¬ì„± ë¶€ì¡±",
                    description="ì‚¬ìš©ì ê´€ì ì˜ ê°€ì¹˜ ì–¸ê¸‰ì´ ë¶€ì¡±í•¨",
                    location="ì „ì²´ ë¬¸ì„œ",
                    suggested_fix="ì‚¬ìš©ì ë‹ˆì¦ˆì™€ ê°€ì¹˜ ì°½ì¶œ ë°©ì•ˆ ëª…ì‹œ",
                    blocking=False,
                    evidence=[f"ì‚¬ìš©ì ê´€ë ¨ ì–¸ê¸‰: {user_mentions}íšŒ"]
                ))
                score -= 0.2
        
        return max(0.0, score), issues, recommendations
    
    def _evaluate_documentation_quality(self, 
                                      criterion: ReviewCriterion, 
                                      content: Dict[str, Any], 
                                      review_result: ReviewResult) -> Tuple[float, List[ReviewIssue], List[str]]:
        """ë¬¸ì„œí™” í’ˆì§ˆ í‰ê°€"""
        
        issues = []
        recommendations = []
        score = 1.0
        
        if content.get("file_type") == "text":
            sections = content.get("sections", [])
            text_content = content.get("content", "")
            
            # êµ¬ì¡° ì™„ì„±ë„ í™•ì¸
            essential_sections = ["ê°œìš”", "ìš”êµ¬ì‚¬í•­", "ëª…ì„¸", "ê²°ë¡ "]
            missing_sections = []
            
            for essential in essential_sections:
                if not any(essential in section for section in sections):
                    missing_sections.append(essential)
            
            if missing_sections:
                issues.append(ReviewIssue(
                    issue_id=f"doc_qual_001",
                    criterion_id=criterion.criterion_id,
                    severity=CriticalityLevel.MEDIUM,
                    title="í•„ìˆ˜ ì„¹ì…˜ ëˆ„ë½",
                    description=f"í•„ìˆ˜ ì„¹ì…˜ì´ ëˆ„ë½ë¨: {', '.join(missing_sections)}",
                    location="ë¬¸ì„œ êµ¬ì¡°",
                    suggested_fix="ëˆ„ë½ëœ ì„¹ì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”",
                    blocking=True,
                    evidence=missing_sections
                ))
                score -= len(missing_sections) * 0.2
            
            # ê°€ë…ì„± í™•ì¸
            avg_sentence_length = self._calculate_average_sentence_length(text_content)
            if avg_sentence_length > 25:
                issues.append(ReviewIssue(
                    issue_id=f"doc_qual_002",
                    criterion_id=criterion.criterion_id,
                    severity=CriticalityLevel.LOW,
                    title="ë¬¸ì¥ ê¸¸ì´ ê³¼ë‹¤",
                    description=f"í‰ê·  ë¬¸ì¥ ê¸¸ì´ê°€ {avg_sentence_length:.1f}ë¡œ ë„ˆë¬´ ê¹€",
                    location="ì „ì²´ ë¬¸ì„œ",
                    suggested_fix="ë¬¸ì¥ì„ ë” ì§§ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”",
                    blocking=False,
                    evidence=[f"í‰ê·  ë¬¸ì¥ ê¸¸ì´: {avg_sentence_length:.1f}"]
                ))
                score -= 0.1
        
        return max(0.0, score), issues, recommendations
    
    def _evaluate_consistency(self, 
                            criterion: ReviewCriterion, 
                            content: Dict[str, Any], 
                            review_result: ReviewResult) -> Tuple[float, List[ReviewIssue], List[str]]:
        """ì¼ê´€ì„± í‰ê°€"""
        
        issues = []
        recommendations = []
        score = 1.0
        
        if content.get("file_type") == "text":
            text_content = content.get("content", "")
            
            # ìš©ì–´ ì¼ê´€ì„± í™•ì¸
            inconsistencies = self._check_term_consistency(text_content)
            
            for inconsistency in inconsistencies:
                issues.append(ReviewIssue(
                    issue_id=f"consist_001_{len(issues)}",
                    criterion_id=criterion.criterion_id,
                    severity=CriticalityLevel.LOW,
                    title=f"ìš©ì–´ ë¶ˆì¼ì¹˜: {inconsistency['terms']}",
                    description="ë™ì¼í•œ ê°œë…ì— ëŒ€í•´ ë‹¤ë¥¸ ìš©ì–´ ì‚¬ìš©",
                    location="ì „ì²´ ë¬¸ì„œ",
                    suggested_fix=f"'{inconsistency['recommended']}'ë¡œ í†µì¼",
                    blocking=False,
                    evidence=inconsistency['examples']
                ))
                score -= 0.05
        
        return max(0.0, score), issues, recommendations
    
    def _evaluate_generic_criterion(self, 
                                   criterion: ReviewCriterion, 
                                   content: Dict[str, Any], 
                                   review_result: ReviewResult) -> Tuple[float, List[ReviewIssue], List[str]]:
        """ì¼ë°˜ì  ê¸°ì¤€ í‰ê°€"""
        
        issues = []
        recommendations = ["ìƒì„¸í•œ ê²€í† ë¥¼ ìœ„í•´ ì „ë¬¸ê°€ ë¦¬ë·°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤"]
        
        # ê¸°ë³¸ì ì¸ ì™„ì„±ë„ í‰ê°€
        if content.get("error"):
            score = 0.0
        elif content.get("word_count", 0) < 100:
            score = 0.3  # ë„ˆë¬´ ì§§ìŒ
        else:
            score = 0.8  # ê¸°ë³¸ ì ìˆ˜
        
        return score, issues, recommendations
    
    def _make_approval_decision(self, review_result: ReviewResult) -> Dict[str, Any]:
        """ìŠ¹ì¸/ê±°ë¶€ ê²°ì •"""
        
        # ë¸”ë¡œí‚¹ ì´ìŠˆ í™•ì¸
        blocking_issues = [issue for issue in review_result.issues if issue.blocking]
        critical_issues = [issue for issue in review_result.issues 
                          if issue.severity == CriticalityLevel.CRITICAL]
        
        # ê²°ì • ë¡œì§
        if blocking_issues or critical_issues:
            status = ReviewStatus.REJECTED
            rationale = f"ë¸”ë¡œí‚¹ ì´ìŠˆ {len(blocking_issues)}ê°œ, ì¹˜ëª…ì  ì´ìŠˆ {len(critical_issues)}ê°œ ë°œê²¬"
            revision_required = True
        elif review_result.overall_score < 0.6:
            status = ReviewStatus.NEEDS_REVISION
            rationale = f"ì „ì²´ ì ìˆ˜ {review_result.overall_score:.2f}ë¡œ ê¸°ì¤€ ë¯¸ë‹¬ (ìµœì†Œ 0.6 í•„ìš”)"
            revision_required = True
        elif review_result.overall_score < 0.8:
            status = ReviewStatus.CONDITIONAL_APPROVAL
            rationale = f"ì¡°ê±´ë¶€ ìŠ¹ì¸ (ì ìˆ˜: {review_result.overall_score:.2f})"
            revision_required = False
        else:
            status = ReviewStatus.APPROVED
            rationale = f"ìš°ìˆ˜í•œ í’ˆì§ˆë¡œ ìŠ¹ì¸ (ì ìˆ˜: {review_result.overall_score:.2f})"
            revision_required = False
        
        # ë‹¤ìŒ ë¦¬ë·°ì–´ ê²°ì •
        next_reviewer = None
        if status == ReviewStatus.APPROVED and review_result.review_type != ReviewType.FINAL_APPROVAL:
            if review_result.review_type == ReviewType.TECHNICAL_REVIEW:
                next_reviewer = "product_owner"  # ê¸°ìˆ  ë¦¬ë·° í›„ ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ë·°
            elif review_result.review_type == ReviewType.BUSINESS_REVIEW:
                next_reviewer = "project_manager"  # ìµœì¢… ìŠ¹ì¸
        
        return {
            "status": status,
            "rationale": rationale,
            "revision_required": revision_required,
            "next_reviewer": next_reviewer
        }
    
    def _send_review_request(self, review_result: ReviewResult, custom_criteria: List[str] = None):
        """ë¦¬ë·° ìš”ì²­ ë©”ì‹œì§€ ì „ì†¡"""
        
        # ë¦¬ë·° ìš”ì²­ì„œ ìƒì„±
        request_content = {
            "review_id": review_result.review_id,
            "type": "review_request",
            "deliverable_path": review_result.deliverable_path,
            "review_type": review_result.review_type.value,
            "urgency": "high",
            "criteria": [asdict(criterion) for criterion in 
                        self.review_criteria.get(review_result.review_type.value, [])],
            "custom_criteria": custom_criteria or [],
            "instructions": self._generate_review_instructions(review_result),
            "deadline": (datetime.now() + timedelta(hours=6)).isoformat()
        }
        
        # í†µì‹  ë””ë ‰í† ë¦¬ì— ìš”ì²­ ì €ì¥
        comm_dir = self.project_root / "communication" / f"to_{review_result.reviewer_role}"
        comm_dir.mkdir(parents=True, exist_ok=True)
        
        request_file = comm_dir / f"review_request_{review_result.review_id}.yaml"
        
        with open(request_file, 'w', encoding='utf-8') as f:
            yaml.dump(request_content, f, default_flow_style=False, allow_unicode=True)
        
        print(f"ğŸ“§ ë¦¬ë·° ìš”ì²­ ì „ì†¡: {review_result.reviewer_role} <- {review_result.review_id}")
    
    def _generate_review_instructions(self, review_result: ReviewResult) -> str:
        """ë¦¬ë·° ì§€ì‹œì‚¬í•­ ìƒì„±"""
        
        instructions = f"""
# ë¦¬ë·° ì§€ì‹œì‚¬í•­: {review_result.review_id}

## ğŸ¯ ë¦¬ë·° ë¯¸ì…˜
ë‹¹ì‹ ì€ **{review_result.reviewer_role}**ë¡œì„œ **{review_result.reviewee_role}**ì´ ì‘ì„±í•œ ì‚°ì¶œë¬¼ì„ **ë§¤ìš° ì—„ê²©í•˜ê³  ì´ì„±ì ìœ¼ë¡œ** ë¦¬ë·°í•´ì•¼ í•©ë‹ˆë‹¤.

## ğŸ“‹ ë¦¬ë·° ëŒ€ìƒ
- **íŒŒì¼**: {review_result.deliverable_path}
- **íƒ€ì…**: {review_result.review_type.value}
- **ì‘ì„±ì**: {review_result.reviewee_role}

## ğŸ” ë¦¬ë·° ì›ì¹™

### 1. ê·¹ë„ë¡œ ì—„ê²©í•œ ê¸°ì¤€ ì ìš©
- **ì™„ë²½ì£¼ì˜ ì ‘ê·¼**: ì‘ì€ ê²°í•¨ë„ ë†“ì¹˜ì§€ ë§ ê²ƒ
- **ì „ë¬¸ê°€ ìˆ˜ì¤€ ê²€ì¦**: ë‹¹ì‹ ì˜ ì „ë¬¸ ì˜ì—­ì—ì„œ ìµœê³  ìˆ˜ì¤€ ìš”êµ¬
- **AI ëŒ€ AI**: ì¸ê°„ì˜ ê°ì •ì  ë°°ë ¤ ì—†ì´ ìˆœìˆ˜ ë…¼ë¦¬ì  íŒë‹¨

### 2. ì² ì €í•œ ê²€ì¦ í”„ë¡œì„¸ìŠ¤
- **ë¼ì¸ë³„ ìƒì„¸ ê²€í† **: ëª¨ë“  ë‚´ìš©ì„ ê¼¼ê¼¼íˆ ë¶„ì„
- **ë…¼ë¦¬ì  ì¼ê´€ì„±**: ë‚´ìš© ê°„ ëª¨ìˆœì´ë‚˜ ë¹„ë…¼ë¦¬ì  ë¶€ë¶„ ì°¾ê¸°
- **ì‹¤í˜„ ê°€ëŠ¥ì„±**: ì œì•ˆëœ ë‚´ìš©ì˜ ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥ì„± ì—„ê²© í‰ê°€

### 3. ê±´ì„¤ì ì´ì§€ë§Œ ì—„ê²©í•œ í”¼ë“œë°±
- **êµ¬ì²´ì  ì§€ì **: ëª¨í˜¸í•œ ì§€ì  ê¸ˆì§€, ì •í™•í•œ ìœ„ì¹˜ì™€ ì´ìœ  ëª…ì‹œ
- **ê°œì„  ë°©ì•ˆ ì œì‹œ**: ë¬¸ì œì ê³¼ í•¨ê»˜ êµ¬ì²´ì  í•´ê²°ì±… ì œê³µ
- **ìš°ì„ ìˆœìœ„ ë¶„ë¥˜**: ì¹˜ëª…ì /ì¤‘ìš”/ë³´í†µ/ê²½ë¯¸ë¡œ ì´ìŠˆ ë¶„ë¥˜

## ğŸ“Š í‰ê°€ ê¸°ì¤€
ë¦¬ë·° ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì§€ë§Œ, ë‹¹ì‹ ì˜ ì „ë¬¸ì  íŒë‹¨ì´ ìµœì¢… ê²°ì •ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.

## âš¡ ì¦‰ì‹œ ì‹¤í–‰ ì‚¬í•­
1. **íŒŒì¼ í™•ì¸**: `cat {review_result.deliverable_path}`
2. **ë¦¬ë·° ìˆ˜í–‰**: `python3 ../../intelligent_review_system.py --conduct-review {review_result.review_id}`
3. **ê²°ê³¼ í™•ì¸**: ë¦¬ë·° ê²°ê³¼ë¥¼ ê²€í† í•˜ê³  í•„ìš”ì‹œ ì¶”ê°€ ì˜ê²¬ ì œì‹œ

## ğŸš¨ ì¤‘ìš” ì•Œë¦¼
- **ìŠ¹ì¸ ì„ê³„ì **: 0.8ì  ì´ìƒë§Œ ë¬´ì¡°ê±´ ìŠ¹ì¸
- **ê±°ë¶€ ê¸°ì¤€**: ì¹˜ëª…ì  ì´ìŠˆ 1ê°œë¼ë„ ë°œê²¬ ì‹œ ì¦‰ì‹œ ê±°ë¶€
- **ì¬ì‘ì—… ìš”êµ¬**: 0.6ì  ë¯¸ë§Œì€ ë°˜ë“œì‹œ ì¬ì‘ì—… ìš”êµ¬

**ì§€ê¸ˆ ì¦‰ì‹œ ì—„ê²©í•œ ë¦¬ë·°ë¥¼ ì‹œì‘í•˜ì„¸ìš”!** ğŸ”
"""
        
        return instructions
    
    def _notify_review_completion(self, review_result: ReviewResult):
        """ë¦¬ë·° ì™„ë£Œ í†µì§€"""
        
        # ì‘ì„±ìì—ê²Œ ë¦¬ë·° ê²°ê³¼ í†µì§€
        notification = {
            "type": "review_completed",
            "review_id": review_result.review_id,
            "status": review_result.status.value,
            "overall_score": review_result.overall_score,
            "reviewer": review_result.reviewer_role,
            "issues_count": len(review_result.issues),
            "critical_issues": len([i for i in review_result.issues if i.severity == CriticalityLevel.CRITICAL]),
            "blocking_issues": len([i for i in review_result.issues if i.blocking]),
            "decision_rationale": review_result.decision_rationale,
            "revision_required": review_result.revision_required,
            "next_reviewer": review_result.next_reviewer,
            "recommendations": review_result.recommendations[:3],  # ìƒìœ„ 3ê°œë§Œ
            "detailed_results_path": f"reviews/{review_result.review_id}.json"
        }
        
        # ì‘ì„±ìì—ê²Œ í†µì§€
        comm_dir = self.project_root / "communication" / f"to_{review_result.reviewee_role}"
        comm_dir.mkdir(parents=True, exist_ok=True)
        
        notification_file = comm_dir / f"review_result_{review_result.review_id}.yaml"
        
        with open(notification_file, 'w', encoding='utf-8') as f:
            yaml.dump(notification, f, default_flow_style=False, allow_unicode=True)
        
        print(f"ğŸ“¬ ë¦¬ë·° ê²°ê³¼ í†µì§€: {review_result.reviewee_role} <- {review_result.status.value}")
    
    def _save_review_result(self, review_result: ReviewResult):
        """ë¦¬ë·° ê²°ê³¼ ì €ì¥"""
        
        result_file = self.reviews_dir / f"{review_result.review_id}.json"
        
        # dataclassë¥¼ dictë¡œ ë³€í™˜í•˜ë©´ì„œ enum ì²˜ë¦¬
        result_dict = asdict(review_result)
        result_dict['review_type'] = review_result.review_type.value
        result_dict['status'] = review_result.status.value
        
        # ì´ìŠˆë“¤ì˜ enum ê°’ë„ ì²˜ë¦¬
        for issue in result_dict['issues']:
            issue['severity'] = issue['severity'] if isinstance(issue['severity'], str) else issue['severity'].value
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result_dict, f, indent=2, ensure_ascii=False, default=str)
    
    # Helper methods for content analysis
    def _extract_markdown_sections(self, content: str) -> List[str]:
        """ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ ì¶”ì¶œ"""
        import re
        sections = re.findall(r'^#+\s+(.+)$', content, re.MULTILINE)
        return sections
    
    def _analyze_json_structure(self, data: Any) -> Dict[str, Any]:
        """JSON êµ¬ì¡° ë¶„ì„"""
        def analyze_value(value):
            if isinstance(value, dict):
                return {"type": "object", "keys": len(value), "nested": True}
            elif isinstance(value, list):
                return {"type": "array", "length": len(value), "nested": len(value) > 0}
            else:
                return {"type": type(value).__name__, "nested": False}
        
        if isinstance(data, dict):
            return {key: analyze_value(value) for key, value in data.items()}
        return {"root": analyze_value(data)}
    
    def _analyze_yaml_structure(self, data: Any) -> Dict[str, Any]:
        """YAML êµ¬ì¡° ë¶„ì„"""
        return self._analyze_json_structure(data)  # JSONê³¼ ë™ì¼í•œ êµ¬ì¡° ë¶„ì„
    
    def _check_technical_term_consistency(self, content: str, tech_terms: List[str]) -> List[Dict[str, Any]]:
        """ê¸°ìˆ  ìš©ì–´ ì¼ê´€ì„± í™•ì¸"""
        inconsistencies = []
        
        for term in tech_terms:
            # ëŒ€ì†Œë¬¸ì ë‹¤ë¥¸ í˜•íƒœë“¤ ì°¾ê¸°
            import re
            pattern = re.compile(re.escape(term), re.IGNORECASE)
            matches = pattern.findall(content)
            
            if len(set(matches)) > 1:  # ë‹¤ë¥¸ í˜•íƒœë¡œ ì‚¬ìš©ë¨
                inconsistencies.append({
                    "term": term,
                    "standard_form": term,
                    "variants": list(set(matches)),
                    "examples": matches[:3],
                    "lines": [i+1 for i, line in enumerate(content.splitlines()) 
                             if term.lower() in line.lower()][:3]
                })
        
        return inconsistencies
    
    def _validate_api_specifications(self, content: str) -> List[ReviewIssue]:
        """API ëª…ì„¸ ê²€ì¦"""
        issues = []
        
        # HTTP ë©”ì„œë“œ í™•ì¸
        http_methods = ["GET", "POST", "PUT", "DELETE", "PATCH"]
        found_methods = [method for method in http_methods if method in content]
        
        if not found_methods:
            issues.append(ReviewIssue(
                issue_id="api_val_001",
                criterion_id="tech_accuracy",
                severity=CriticalityLevel.MEDIUM,
                title="HTTP ë©”ì„œë“œ ëˆ„ë½",
                description="API ëª…ì„¸ì— HTTP ë©”ì„œë“œê°€ ëª…ì‹œë˜ì§€ ì•ŠìŒ",
                location="API ì„¹ì…˜",
                suggested_fix="GET, POST ë“± HTTP ë©”ì„œë“œ ëª…ì‹œ",
                blocking=False,
                evidence=[]
            ))
        
        # ì—”ë“œí¬ì¸íŠ¸ í˜•ì‹ í™•ì¸
        import re
        endpoints = re.findall(r'/api/[^\s]+', content)
        for endpoint in endpoints:
            if not re.match(r'^/api/v\d+/', endpoint):
                issues.append(ReviewIssue(
                    issue_id=f"api_val_002_{len(issues)}",
                    criterion_id="tech_accuracy",
                    severity=CriticalityLevel.LOW,
                    title="API ë²„ì „ ëˆ„ë½",
                    description=f"ì—”ë“œí¬ì¸íŠ¸ {endpoint}ì— ë²„ì „ ì •ë³´ ëˆ„ë½",
                    location=f"ì—”ë“œí¬ì¸íŠ¸: {endpoint}",
                    suggested_fix="/api/v1/ í˜•íƒœë¡œ ë²„ì „ ëª…ì‹œ",
                    blocking=False,
                    evidence=[endpoint]
                ))
        
        return issues
    
    def _validate_database_specifications(self, content: str) -> List[ReviewIssue]:
        """ë°ì´í„°ë² ì´ìŠ¤ ëª…ì„¸ ê²€ì¦"""
        issues = []
        
        # ê¸°ë³¸ í‚¤ í™•ì¸
        if "primary key" not in content.lower() and "pk" not in content.lower():
            issues.append(ReviewIssue(
                issue_id="db_val_001",
                criterion_id="tech_accuracy",
                severity=CriticalityLevel.HIGH,
                title="ê¸°ë³¸ í‚¤ ëˆ„ë½",
                description="ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”ì— ê¸°ë³¸ í‚¤ê°€ ëª…ì‹œë˜ì§€ ì•ŠìŒ",
                location="ë°ì´í„°ë² ì´ìŠ¤ ì„¹ì…˜",
                suggested_fix="ê° í…Œì´ë¸”ì— ê¸°ë³¸ í‚¤ ì •ì˜ ì¶”ê°€",
                blocking=True,
                evidence=[]
            ))
        
        return issues
    
    def _check_term_consistency(self, content: str) -> List[Dict[str, Any]]:
        """ìš©ì–´ ì¼ê´€ì„± í™•ì¸"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ NLP ë¶„ì„ í•„ìš”
        inconsistencies = []
        
        # ë™ì˜ì–´ ê·¸ë£¹ë“¤
        synonym_groups = [
            ["ì‚¬ìš©ì", "ìœ ì €", "user"],
            ["ê²Œì‹œê¸€", "í¬ìŠ¤íŠ¸", "post"],
            ["ëŒ“ê¸€", "ì½”ë©˜íŠ¸", "comment"],
            ["ë¡œê·¸ì¸", "signin", "sign-in"]
        ]
        
        for group in synonym_groups:
            found_terms = [term for term in group if term in content]
            if len(found_terms) > 1:
                inconsistencies.append({
                    "terms": found_terms,
                    "recommended": group[0],  # ì²« ë²ˆì§¸ë¥¼ ê¶Œì¥ ìš©ì–´ë¡œ
                    "examples": found_terms[:2]
                })
        
        return inconsistencies
    
    def _calculate_average_sentence_length(self, content: str) -> float:
        """í‰ê·  ë¬¸ì¥ ê¸¸ì´ ê³„ì‚°"""
        sentences = content.split('.')
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if not sentences:
            return 0.0
        
        total_words = sum(len(sentence.split()) for sentence in sentences)
        return total_words / len(sentences)

def main():
    """í…ŒìŠ¤íŠ¸ ë° ë°ëª¨"""
    review_engine = IntelligentReviewEngine("/home/jungh/workspace/web_community_project")
    
    # ì˜ˆì‹œ: ë¦¬ë·° ìš”ì²­
    review_id = review_engine.request_review(
        deliverable_path="roles/business_analyst/deliverables/business_requirements.md",
        reviewee_role="business_analyst",
        review_type=ReviewType.BUSINESS_REVIEW,
        priority=CriticalityLevel.HIGH
    )
    
    # ë¦¬ë·° ìˆ˜í–‰
    result = review_engine.conduct_intelligent_review(review_id)
    
    print(f"âœ… ë¦¬ë·° ì™„ë£Œ: {result.status.value} (ì ìˆ˜: {result.overall_score:.2f})")
    print(f"ğŸ“‹ ì´ìŠˆ ìˆ˜: {len(result.issues)}")
    print(f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: {len(result.recommendations)}")

if __name__ == "__main__":
    main()