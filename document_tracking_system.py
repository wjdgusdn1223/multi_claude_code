#!/usr/bin/env python3
"""
Document Tracking System for Multi-Agent Claude Code
ì‚°ì¶œë¬¼ ì½ê¸°/ì‚¬ìš© ì¶”ì  ë° ì§€ëŠ¥ì  ë¬¸ì„œ ê´€ë¦¬ ì‹œìŠ¤í…œ
"""

import os
import json
import yaml
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass, asdict
from enum import Enum

class DocumentType(Enum):
    REQUIREMENT = "requirement"
    SPECIFICATION = "specification"
    DESIGN = "design"
    CODE = "code"
    TEST = "test"
    REPORT = "report"
    PLAN = "plan"
    REVIEW = "review"

class AccessType(Enum):
    READ = "read"
    REFERENCED = "referenced"
    MODIFIED = "modified"
    VALIDATED = "validated"
    APPROVED = "approved"
    REJECTED = "rejected"

@dataclass
class DocumentMetadata:
    """ë¬¸ì„œ ë©”íƒ€ë°ì´í„°"""
    file_path: str
    document_type: DocumentType
    role_owner: str
    title: str
    description: str
    created_at: datetime
    last_modified: datetime
    version: str
    dependencies: List[str]
    dependents: List[str]
    tags: List[str]
    purpose: str
    target_readers: List[str]
    content_hash: str
    size_bytes: int
    
@dataclass
class DocumentAccess:
    """ë¬¸ì„œ ì ‘ê·¼ ê¸°ë¡"""
    access_id: str
    document_path: str
    role_id: str
    access_type: AccessType
    timestamp: datetime
    duration_seconds: Optional[int]
    content_read_percentage: Optional[float]
    purpose: str
    notes: str
    context: Dict[str, Any]

@dataclass
class DocumentUsage:
    """ë¬¸ì„œ ì‚¬ìš© ë¶„ì„"""
    document_path: str
    total_accesses: int
    unique_readers: Set[str]
    last_accessed: datetime
    average_read_time: float
    content_utilization: float
    feedback_count: int
    issues_raised: int
    approval_status: str

class DocumentTrackingSystem:
    """ë¬¸ì„œ ì¶”ì  ì‹œìŠ¤í…œ"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.tracking_dir = self.project_root / "tracking"
        self.tracking_dir.mkdir(exist_ok=True)
        
        self.metadata_file = self.tracking_dir / "document_metadata.json"
        self.access_log_file = self.tracking_dir / "document_access_log.json"
        self.usage_stats_file = self.tracking_dir / "document_usage_stats.json"
        
        self.metadata_registry = self._load_metadata_registry()
        self.access_logs = self._load_access_logs()
        self.usage_stats = self._load_usage_stats()
    
    def register_document(self, 
                         file_path: str, 
                         role_owner: str, 
                         document_type: DocumentType,
                         metadata: Dict[str, Any]) -> bool:
        """ë¬¸ì„œ ë“±ë¡"""
        try:
            full_path = self.project_root / file_path
            
            if not full_path.exists():
                print(f"ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
                return False
            
            # íŒŒì¼ ë‚´ìš© í•´ì‹œ ê³„ì‚°
            content_hash = self._calculate_file_hash(full_path)
            file_size = full_path.stat().st_size
            
            doc_metadata = DocumentMetadata(
                file_path=file_path,
                document_type=document_type,
                role_owner=role_owner,
                title=metadata.get('title', full_path.name),
                description=metadata.get('description', ''),
                created_at=datetime.now(),
                last_modified=datetime.fromtimestamp(full_path.stat().st_mtime),
                version=metadata.get('version', '1.0'),
                dependencies=metadata.get('dependencies', []),
                dependents=metadata.get('dependents', []),
                tags=metadata.get('tags', []),
                purpose=metadata.get('purpose', ''),
                target_readers=metadata.get('target_readers', []),
                content_hash=content_hash,
                size_bytes=file_size
            )
            
            self.metadata_registry[file_path] = asdict(doc_metadata)
            self._save_metadata_registry()
            
            print(f"âœ… ë¬¸ì„œ ë“±ë¡ ì™„ë£Œ: {file_path}")
            return True
            
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ë“±ë¡ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def log_document_access(self,
                           document_path: str,
                           role_id: str,
                           access_type: AccessType,
                           purpose: str = "",
                           duration_seconds: Optional[int] = None,
                           content_read_percentage: Optional[float] = None,
                           notes: str = "",
                           context: Dict[str, Any] = None) -> str:
        """ë¬¸ì„œ ì ‘ê·¼ ë¡œê¹…"""
        access_id = f"{role_id}_{document_path.replace('/', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        access_record = DocumentAccess(
            access_id=access_id,
            document_path=document_path,
            role_id=role_id,
            access_type=access_type,
            timestamp=datetime.now(),
            duration_seconds=duration_seconds,
            content_read_percentage=content_read_percentage,
            purpose=purpose,
            notes=notes,
            context=context or {}
        )
        
        # ì ‘ê·¼ ë¡œê·¸ ì €ì¥
        access_key = f"{datetime.now().isoformat()}_{access_id}"
        self.access_logs[access_key] = asdict(access_record)
        self._save_access_logs()
        
        # ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸
        self._update_usage_stats(access_record)
        
        print(f"ğŸ“– ë¬¸ì„œ ì ‘ê·¼ ê¸°ë¡: {role_id} -> {document_path} ({access_type.value})")
        return access_id
    
    def get_document_metadata(self, document_path: str) -> Optional[DocumentMetadata]:
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        metadata_dict = self.metadata_registry.get(document_path)
        if metadata_dict:
            # datetime ê°ì²´ ë³µì›
            metadata_dict['created_at'] = datetime.fromisoformat(metadata_dict['created_at'])
            metadata_dict['last_modified'] = datetime.fromisoformat(metadata_dict['last_modified'])
            metadata_dict['document_type'] = DocumentType(metadata_dict['document_type'])
            return DocumentMetadata(**metadata_dict)
        return None
    
    def get_documents_for_role(self, role_id: str, include_recommendations: bool = True) -> List[Dict[str, Any]]:
        """ì—­í• ë³„ í•„ìš” ë¬¸ì„œ ëª©ë¡"""
        relevant_docs = []
        
        for doc_path, metadata in self.metadata_registry.items():
            doc_metadata = self.get_document_metadata(doc_path)
            if not doc_metadata:
                continue
            
            # ì§ì ‘ì ìœ¼ë¡œ ì§€ì •ëœ ë…ìì¸ì§€ í™•ì¸
            is_target_reader = role_id in doc_metadata.target_readers
            
            # ì˜ì¡´ì„± ê¸°ë°˜ ì¶”ì²œ
            is_dependency = self._is_dependency_for_role(role_id, doc_path)
            
            # ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°
            relevance_score = self._calculate_relevance_score(role_id, doc_metadata)
            
            if is_target_reader or is_dependency or (include_recommendations and relevance_score > 0.5):
                doc_info = {
                    'path': doc_path,
                    'metadata': asdict(doc_metadata),
                    'is_target_reader': is_target_reader,
                    'is_dependency': is_dependency,
                    'relevance_score': relevance_score,
                    'read_status': self._get_read_status(role_id, doc_path),
                    'last_accessed': self._get_last_access_time(role_id, doc_path),
                    'priority': self._calculate_document_priority(role_id, doc_metadata)
                }
                relevant_docs.append(doc_info)
        
        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
        relevant_docs.sort(key=lambda x: (x['priority'], -x['relevance_score']), reverse=True)
        
        return relevant_docs
    
    def get_unread_critical_documents(self, role_id: str) -> List[Dict[str, Any]]:
        """ì½ì§€ ì•Šì€ ì¤‘ìš” ë¬¸ì„œ ëª©ë¡"""
        unread_critical = []
        
        for doc_path, metadata in self.metadata_registry.items():
            doc_metadata = self.get_document_metadata(doc_path)
            if not doc_metadata:
                continue
            
            # ì¤‘ìš”ë„ í‰ê°€
            is_critical = self._is_critical_for_role(role_id, doc_metadata)
            is_read = self._has_role_read_document(role_id, doc_path)
            
            if is_critical and not is_read:
                doc_info = {
                    'path': doc_path,
                    'title': doc_metadata.title,
                    'owner': doc_metadata.role_owner,
                    'urgency': self._calculate_urgency(doc_metadata),
                    'blocking_factor': self._calculate_blocking_factor(role_id, doc_path),
                    'estimated_read_time': self._estimate_read_time(doc_metadata),
                    'summary': doc_metadata.description
                }
                unread_critical.append(doc_info)
        
        # ê¸´ê¸‰ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        unread_critical.sort(key=lambda x: (x['urgency'], x['blocking_factor']), reverse=True)
        
        return unread_critical
    
    def track_document_usage_in_task(self, role_id: str, task_name: str, documents_used: List[str]) -> Dict[str, Any]:
        """ì‘ì—… ì¤‘ ë¬¸ì„œ ì‚¬ìš© ì¶”ì """
        usage_record = {
            'role_id': role_id,
            'task_name': task_name,
            'timestamp': datetime.now().isoformat(),
            'documents_used': documents_used,
            'usage_analysis': {}
        }
        
        for doc_path in documents_used:
            # ë¬¸ì„œ ì‚¬ìš© ê¸°ë¡
            access_id = self.log_document_access(
                document_path=doc_path,
                role_id=role_id,
                access_type=AccessType.REFERENCED,
                purpose=f"Task: {task_name}ì—ì„œ ì°¸ì¡°",
                context={'task': task_name, 'usage_type': 'task_execution'}
            )
            
            # ì‚¬ìš© ë¶„ì„
            doc_metadata = self.get_document_metadata(doc_path)
            if doc_metadata:
                usage_record['usage_analysis'][doc_path] = {
                    'access_id': access_id,
                    'document_type': doc_metadata.document_type.value,
                    'owner': doc_metadata.role_owner,
                    'relevance_to_task': self._assess_document_relevance_to_task(doc_path, task_name),
                    'usage_effectiveness': self._assess_usage_effectiveness(role_id, doc_path, task_name)
                }
        
        # ì‘ì—…-ë¬¸ì„œ ì‚¬ìš© ê¸°ë¡ ì €ì¥
        usage_file = self.tracking_dir / f"task_document_usage_{role_id}.json"
        
        existing_usage = {}
        if usage_file.exists():
            with open(usage_file, 'r', encoding='utf-8') as f:
                existing_usage = json.load(f)
        
        existing_usage[f"{task_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"] = usage_record
        
        with open(usage_file, 'w', encoding='utf-8') as f:
            json.dump(existing_usage, f, indent=2, ensure_ascii=False, default=str)
        
        return usage_record
    
    def generate_document_recommendations(self, role_id: str, current_task: str = "") -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ì¶”ì²œ"""
        recommendations = []
        
        # í˜„ì¬ ì‘ì—…ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ì¶”ì²œ
        if current_task:
            task_related_docs = self._find_task_related_documents(role_id, current_task)
            recommendations.extend(task_related_docs)
        
        # ì—­í•  ê¸°ë°˜ í•„ìˆ˜ ë¬¸ì„œ ì¶”ì²œ
        role_essential_docs = self._find_role_essential_documents(role_id)
        recommendations.extend(role_essential_docs)
        
        # í˜‘ì—… ê¸°ë°˜ ì¶”ì²œ
        collaborative_docs = self._find_collaborative_documents(role_id)
        recommendations.extend(collaborative_docs)
        
        # ì¤‘ë³µ ì œê±° ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
        unique_recommendations = self._deduplicate_recommendations(recommendations)
        unique_recommendations.sort(key=lambda x: x['recommendation_score'], reverse=True)
        
        return unique_recommendations[:10]  # ìƒìœ„ 10ê°œ ì¶”ì²œ
    
    def create_reading_schedule(self, role_id: str) -> Dict[str, Any]:
        """ì½ê¸° ì¼ì • ìƒì„±"""
        unread_docs = self.get_unread_critical_documents(role_id)
        recommended_docs = self.generate_document_recommendations(role_id)
        
        schedule = {
            'role_id': role_id,
            'created_at': datetime.now().isoformat(),
            'immediate_priority': [],  # ì¦‰ì‹œ ì½ì–´ì•¼ í•  ë¬¸ì„œ
            'today_schedule': [],      # ì˜¤ëŠ˜ ì½ì„ ë¬¸ì„œ
            'this_week': [],           # ì´ë²ˆ ì£¼ ì½ì„ ë¬¸ì„œ
            'optional_reading': []     # ì„ íƒì  ì½ê¸°
        }
        
        # ê¸´ê¸‰ë„ì— ë”°ë¥¸ ë¶„ë¥˜
        for doc in unread_docs:
            if doc['urgency'] >= 0.9:
                schedule['immediate_priority'].append(doc)
            elif doc['urgency'] >= 0.7:
                schedule['today_schedule'].append(doc)
            elif doc['urgency'] >= 0.5:
                schedule['this_week'].append(doc)
            else:
                schedule['optional_reading'].append(doc)
        
        # ì¶”ì²œ ë¬¸ì„œ ì¶”ê°€
        for rec_doc in recommended_docs:
            if rec_doc['recommendation_score'] >= 0.8:
                schedule['today_schedule'].append(rec_doc)
            elif rec_doc['recommendation_score'] >= 0.6:
                schedule['this_week'].append(rec_doc)
            else:
                schedule['optional_reading'].append(rec_doc)
        
        # ì½ê¸° ì‹œê°„ ì¶”ì •
        schedule['estimated_time'] = {
            'immediate': sum(doc.get('estimated_read_time', 15) for doc in schedule['immediate_priority']),
            'today': sum(doc.get('estimated_read_time', 15) for doc in schedule['today_schedule']),
            'this_week': sum(doc.get('estimated_read_time', 15) for doc in schedule['this_week'])
        }
        
        return schedule
    
    def update_role_status_with_tracking(self, role_id: str, status_updates: Dict[str, Any]) -> Dict[str, Any]:
        """ì—­í•  ìƒíƒœì— ë¬¸ì„œ ì¶”ì  ì •ë³´ í†µí•©"""
        # ê¸°ì¡´ ìƒíƒœ ë¡œë“œ
        status_file = self.project_root / "roles" / role_id / "status.yaml"
        current_status = {}
        
        if status_file.exists():
            with open(status_file, 'r', encoding='utf-8') as f:
                current_status = yaml.safe_load(f)
        
        # ë¬¸ì„œ ì¶”ì  ì •ë³´ ì¶”ê°€
        document_tracking = {
            'documents_accessed_today': self._get_todays_accesses(role_id),
            'unread_critical_count': len(self.get_unread_critical_documents(role_id)),
            'reading_schedule': self.create_reading_schedule(role_id),
            'document_usage_efficiency': self._calculate_usage_efficiency(role_id),
            'knowledge_gaps': self._identify_knowledge_gaps(role_id),
            'last_tracking_update': datetime.now().isoformat()
        }
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        current_status.update(status_updates)
        current_status['document_tracking'] = document_tracking
        
        # ìƒíƒœ ì €ì¥
        with open(status_file, 'w', encoding='utf-8') as f:
            yaml.dump(current_status, f, default_flow_style=False, allow_unicode=True)
        
        return current_status
    
    # Helper methods
    def _load_metadata_registry(self) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                pass
        return {}
    
    def _save_metadata_registry(self):
        """ë©”íƒ€ë°ì´í„° ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥"""
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.metadata_registry, f, indent=2, ensure_ascii=False, default=str)
    
    def _load_access_logs(self) -> Dict[str, Any]:
        """ì ‘ê·¼ ë¡œê·¸ ë¡œë“œ"""
        if self.access_log_file.exists():
            try:
                with open(self.access_log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                pass
        return {}
    
    def _save_access_logs(self):
        """ì ‘ê·¼ ë¡œê·¸ ì €ì¥"""
        with open(self.access_log_file, 'w', encoding='utf-8') as f:
            json.dump(self.access_logs, f, indent=2, ensure_ascii=False, default=str)
    
    def _load_usage_stats(self) -> Dict[str, Any]:
        """ì‚¬ìš© í†µê³„ ë¡œë“œ"""
        if self.usage_stats_file.exists():
            try:
                with open(self.usage_stats_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                pass
        return {}
    
    def _save_usage_stats(self):
        """ì‚¬ìš© í†µê³„ ì €ì¥"""
        with open(self.usage_stats_file, 'w', encoding='utf-8') as f:
            json.dump(self.usage_stats, f, indent=2, ensure_ascii=False, default=str)
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
        except Exception:
            return ""
        return hash_md5.hexdigest()
    
    def _update_usage_stats(self, access_record: DocumentAccess):
        """ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸"""
        doc_path = access_record.document_path
        
        if doc_path not in self.usage_stats:
            self.usage_stats[doc_path] = {
                'total_accesses': 0,
                'unique_readers': set(),
                'last_accessed': None,
                'read_times': [],
                'feedback_count': 0,
                'issues_raised': 0,
                'approval_status': 'pending'
            }
        
        stats = self.usage_stats[doc_path]
        stats['total_accesses'] += 1
        stats['unique_readers'].add(access_record.role_id)
        stats['last_accessed'] = access_record.timestamp.isoformat()
        
        if access_record.duration_seconds:
            stats['read_times'].append(access_record.duration_seconds)
        
        # Setì„ listë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ í•¨
        stats['unique_readers'] = list(stats['unique_readers'])
        
        self._save_usage_stats()
    
    def _is_dependency_for_role(self, role_id: str, doc_path: str) -> bool:
        """ì—­í• ì— ëŒ€í•œ ì˜ì¡´ì„± ë¬¸ì„œì¸ì§€ í™•ì¸"""
        # ì—­í•  ê°„ ì˜ì¡´ì„± ë§¤í•‘ì„ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
        role_dependencies = {
            'requirements_analyst': ['business_requirements.md', 'functional_specifications.md'],
            'system_architect': ['technical_requirements.md', 'business_requirements.md'],
            'frontend_developer': ['ui_designs.md', 'system_architecture.md']
        }
        
        required_docs = role_dependencies.get(role_id, [])
        return any(req_doc in doc_path for req_doc in required_docs)
    
    def _calculate_relevance_score(self, role_id: str, doc_metadata: DocumentMetadata) -> float:
        """ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # íƒ€ê²Ÿ ë…ìì¸ ê²½ìš°
        if role_id in doc_metadata.target_readers:
            score += 0.8
        
        # ë¬¸ì„œ íƒ€ì… ê¸°ë°˜ ê´€ë ¨ë„
        role_doc_relevance = {
            'business_analyst': [DocumentType.REQUIREMENT, DocumentType.SPECIFICATION],
            'system_architect': [DocumentType.DESIGN, DocumentType.SPECIFICATION],
            'frontend_developer': [DocumentType.DESIGN, DocumentType.CODE]
        }
        
        if role_id in role_doc_relevance:
            if doc_metadata.document_type in role_doc_relevance[role_id]:
                score += 0.5
        
        # íƒœê·¸ ê¸°ë°˜ ê´€ë ¨ë„
        role_tags = {
            'frontend_developer': ['ui', 'frontend', 'react', 'javascript'],
            'backend_developer': ['api', 'backend', 'nodejs', 'database'],
            'system_architect': ['architecture', 'system', 'design', 'technical']
        }
        
        if role_id in role_tags:
            matching_tags = set(doc_metadata.tags) & set(role_tags[role_id])
            score += len(matching_tags) * 0.1
        
        return min(score, 1.0)
    
    def _get_read_status(self, role_id: str, doc_path: str) -> Dict[str, Any]:
        """ì½ê¸° ìƒíƒœ ì¡°íšŒ"""
        accesses = [
            access for access in self.access_logs.values()
            if access['role_id'] == role_id and access['document_path'] == doc_path
        ]
        
        if not accesses:
            return {'status': 'unread', 'last_access': None, 'read_count': 0}
        
        latest_access = max(accesses, key=lambda x: x['timestamp'])
        
        return {
            'status': 'read',
            'last_access': latest_access['timestamp'],
            'read_count': len(accesses),
            'total_read_time': sum(a.get('duration_seconds', 0) for a in accesses),
            'average_completion': sum(a.get('content_read_percentage', 0) for a in accesses) / len(accesses)
        }
    
    def _get_last_access_time(self, role_id: str, doc_path: str) -> Optional[str]:
        """ë§ˆì§€ë§‰ ì ‘ê·¼ ì‹œê°„ ì¡°íšŒ"""
        accesses = [
            access for access in self.access_logs.values()
            if access['role_id'] == role_id and access['document_path'] == doc_path
        ]
        
        if accesses:
            latest = max(accesses, key=lambda x: x['timestamp'])
            return latest['timestamp']
        return None
    
    def _calculate_document_priority(self, role_id: str, doc_metadata: DocumentMetadata) -> float:
        """ë¬¸ì„œ ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        priority = 0.0
        
        # íƒ€ê²Ÿ ë…ì ìš°ì„ ìˆœìœ„
        if role_id in doc_metadata.target_readers:
            priority += 0.8
        
        # ë¬¸ì„œ íƒ€ì…ë³„ ìš°ì„ ìˆœìœ„
        type_priority = {
            DocumentType.REQUIREMENT: 0.9,
            DocumentType.SPECIFICATION: 0.8,
            DocumentType.DESIGN: 0.7,
            DocumentType.PLAN: 0.6,
            DocumentType.REPORT: 0.4
        }
        priority += type_priority.get(doc_metadata.document_type, 0.3)
        
        # ìµœì‹ ì„± ê³ ë ¤
        days_old = (datetime.now() - doc_metadata.last_modified).days
        freshness_factor = max(0, 1.0 - (days_old / 30))  # 30ì¼ì´ ì§€ë‚˜ë©´ 0
        priority += freshness_factor * 0.2
        
        return min(priority, 1.0)
    
    def _is_critical_for_role(self, role_id: str, doc_metadata: DocumentMetadata) -> bool:
        """ì—­í• ì— ëŒ€í•œ ì¤‘ìš” ë¬¸ì„œì¸ì§€ íŒë‹¨"""
        # ì§ì ‘ íƒ€ê²Ÿ ë…ìì¸ ê²½ìš°
        if role_id in doc_metadata.target_readers:
            return True
        
        # ì˜ì¡´ì„± ë¬¸ì„œì¸ ê²½ìš°
        if self._is_dependency_for_role(role_id, doc_metadata.file_path):
            return True
        
        # ê´€ë ¨ë„ ì ìˆ˜ê°€ ë†’ì€ ê²½ìš°
        relevance = self._calculate_relevance_score(role_id, doc_metadata)
        return relevance >= 0.7
    
    def _has_role_read_document(self, role_id: str, doc_path: str) -> bool:
        """ì—­í• ì´ ë¬¸ì„œë¥¼ ì½ì—ˆëŠ”ì§€ í™•ì¸"""
        read_status = self._get_read_status(role_id, doc_path)
        return read_status['status'] == 'read'
    
    def _calculate_urgency(self, doc_metadata: DocumentMetadata) -> float:
        """ê¸´ê¸‰ë„ ê³„ì‚°"""
        urgency = 0.5  # ê¸°ë³¸ê°’
        
        # ìµœì‹ ì„± ê¸°ë°˜ ê¸´ê¸‰ë„
        hours_old = (datetime.now() - doc_metadata.last_modified).total_seconds() / 3600
        if hours_old < 2:
            urgency += 0.4
        elif hours_old < 24:
            urgency += 0.2
        
        # ë¬¸ì„œ íƒ€ì…ë³„ ê¸´ê¸‰ë„
        type_urgency = {
            DocumentType.REQUIREMENT: 0.9,
            DocumentType.SPECIFICATION: 0.8,
            DocumentType.DESIGN: 0.6
        }
        urgency += type_urgency.get(doc_metadata.document_type, 0.1)
        
        return min(urgency, 1.0)
    
    def _calculate_blocking_factor(self, role_id: str, doc_path: str) -> float:
        """ë¸”ë¡œí‚¹ ìš”ì†Œ ê³„ì‚°"""
        # ì´ ë¬¸ì„œê°€ ì—­í• ì˜ ì‘ì—…ì„ ì–¼ë§ˆë‚˜ ë¸”ë¡œí‚¹í•˜ëŠ”ì§€ í‰ê°€
        doc_metadata = self.get_document_metadata(doc_path)
        if not doc_metadata:
            return 0.0
        
        # ì˜ì¡´ì„± ë¬¸ì„œì¸ ê²½ìš° ë†’ì€ ë¸”ë¡œí‚¹ ìš”ì†Œ
        if self._is_dependency_for_role(role_id, doc_path):
            return 0.9
        
        # íƒ€ê²Ÿ ë…ìì¸ ê²½ìš°
        if role_id in doc_metadata.target_readers:
            return 0.7
        
        return 0.3
    
    def _estimate_read_time(self, doc_metadata: DocumentMetadata) -> int:
        """ì½ê¸° ì‹œê°„ ì¶”ì • (ë¶„)"""
        # íŒŒì¼ í¬ê¸° ê¸°ë°˜ ì¶”ì • (ëŒ€ëµ 1KBë‹¹ 1ë¶„)
        estimated_minutes = max(5, doc_metadata.size_bytes // 1024)
        
        # ë¬¸ì„œ íƒ€ì…ë³„ ì¡°ì •
        type_multiplier = {
            DocumentType.REQUIREMENT: 1.5,
            DocumentType.SPECIFICATION: 1.8,
            DocumentType.DESIGN: 1.3,
            DocumentType.CODE: 2.0,
            DocumentType.REPORT: 1.0
        }
        
        multiplier = type_multiplier.get(doc_metadata.document_type, 1.0)
        return int(estimated_minutes * multiplier)
    
    def _assess_document_relevance_to_task(self, doc_path: str, task_name: str) -> float:
        """ì‘ì—…ì— ëŒ€í•œ ë¬¸ì„œ ê´€ë ¨ë„ í‰ê°€"""
        # ì‘ì—…ëª…ê³¼ ë¬¸ì„œ ê²½ë¡œ/ë‚´ìš©ì˜ í‚¤ì›Œë“œ ë§¤ì¹­
        task_keywords = task_name.lower().split()
        doc_keywords = doc_path.lower().split('/')
        
        matches = len(set(task_keywords) & set(doc_keywords))
        return min(matches / len(task_keywords), 1.0) if task_keywords else 0.0
    
    def _assess_usage_effectiveness(self, role_id: str, doc_path: str, task_name: str) -> float:
        """ì‚¬ìš© íš¨ê³¼ì„± í‰ê°€"""
        # ê°„ë‹¨í•œ íš¨ê³¼ì„± ì ìˆ˜ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
        return 0.8  # ì„ì‹œê°’
    
    def _find_task_related_documents(self, role_id: str, task_name: str) -> List[Dict[str, Any]]:
        """ì‘ì—… ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°"""
        related_docs = []
        task_keywords = task_name.lower().split()
        
        for doc_path, metadata in self.metadata_registry.items():
            doc_metadata = self.get_document_metadata(doc_path)
            if not doc_metadata:
                continue
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            doc_text = f"{doc_metadata.title} {doc_metadata.description} {' '.join(doc_metadata.tags)}".lower()
            relevance = sum(1 for keyword in task_keywords if keyword in doc_text) / len(task_keywords)
            
            if relevance > 0.3:
                related_docs.append({
                    'path': doc_path,
                    'metadata': asdict(doc_metadata),
                    'recommendation_score': relevance,
                    'recommendation_reason': f"Task '{task_name}' ê´€ë ¨ì„±: {relevance:.2f}"
                })
        
        return related_docs
    
    def _find_role_essential_documents(self, role_id: str) -> List[Dict[str, Any]]:
        """ì—­í•  í•„ìˆ˜ ë¬¸ì„œ ì°¾ê¸°"""
        essential_docs = []
        
        for doc_path, metadata in self.metadata_registry.items():
            doc_metadata = self.get_document_metadata(doc_path)
            if not doc_metadata:
                continue
            
            if role_id in doc_metadata.target_readers:
                essential_docs.append({
                    'path': doc_path,
                    'metadata': asdict(doc_metadata),
                    'recommendation_score': 0.9,
                    'recommendation_reason': "ì—­í• ì˜ í•„ìˆ˜ ì½ê¸° ë¬¸ì„œ"
                })
        
        return essential_docs
    
    def _find_collaborative_documents(self, role_id: str) -> List[Dict[str, Any]]:
        """í˜‘ì—… ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°"""
        # ë‹¤ë¥¸ ì—­í• ë“¤ì´ ìµœê·¼ì— ë§ì´ ì ‘ê·¼í•œ ë¬¸ì„œë“¤
        collaborative_docs = []
        
        # ìµœê·¼ 7ì¼ê°„ì˜ ì ‘ê·¼ ë¡œê·¸ ë¶„ì„
        recent_cutoff = datetime.now() - timedelta(days=7)
        
        doc_access_count = {}
        for access in self.access_logs.values():
            access_time = datetime.fromisoformat(access['timestamp'])
            if access_time > recent_cutoff and access['role_id'] != role_id:
                doc_path = access['document_path']
                doc_access_count[doc_path] = doc_access_count.get(doc_path, 0) + 1
        
        # ì ‘ê·¼ ë¹ˆë„ê°€ ë†’ì€ ë¬¸ì„œë“¤ ì¶”ì²œ
        for doc_path, access_count in doc_access_count.items():
            if access_count >= 3:  # ìµœì†Œ 3ë²ˆ ì´ìƒ ì ‘ê·¼ëœ ë¬¸ì„œ
                doc_metadata = self.get_document_metadata(doc_path)
                if doc_metadata:
                    score = min(access_count / 10, 0.8)  # ìµœëŒ€ 0.8ì 
                    collaborative_docs.append({
                        'path': doc_path,
                        'metadata': asdict(doc_metadata),
                        'recommendation_score': score,
                        'recommendation_reason': f"ë‹¤ë¥¸ ì—­í• ë“¤ì´ {access_count}íšŒ ì ‘ê·¼í•œ ë¬¸ì„œ"
                    })
        
        return collaborative_docs
    
    def _deduplicate_recommendations(self, recommendations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¶”ì²œ ì¤‘ë³µ ì œê±°"""
        seen_paths = set()
        unique_recs = []
        
        for rec in recommendations:
            path = rec['path']
            if path not in seen_paths:
                seen_paths.add(path)
                unique_recs.append(rec)
        
        return unique_recs
    
    def _get_todays_accesses(self, role_id: str) -> List[Dict[str, Any]]:
        """ì˜¤ëŠ˜ì˜ ì ‘ê·¼ ê¸°ë¡"""
        today = datetime.now().date()
        todays_accesses = []
        
        for access in self.access_logs.values():
            if (access['role_id'] == role_id and 
                datetime.fromisoformat(access['timestamp']).date() == today):
                todays_accesses.append(access)
        
        return todays_accesses
    
    def _calculate_usage_efficiency(self, role_id: str) -> float:
        """ì‚¬ìš© íš¨ìœ¨ì„± ê³„ì‚°"""
        # ê°„ë‹¨í•œ íš¨ìœ¨ì„± ì§€í‘œ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ê³„ì‚°)
        recent_accesses = self._get_todays_accesses(role_id)
        
        if not recent_accesses:
            return 0.0
        
        # í‰ê·  ì½ê¸° ì™„ë£Œìœ¨
        completion_rates = [
            access.get('content_read_percentage', 0) 
            for access in recent_accesses 
            if access.get('content_read_percentage') is not None
        ]
        
        if completion_rates:
            return sum(completion_rates) / len(completion_rates) / 100
        
        return 0.5  # ê¸°ë³¸ê°’

    def _identify_knowledge_gaps(self, role_id: str) -> List[str]:
        """ì§€ì‹ ê²©ì°¨ ì‹ë³„"""
        gaps = []
        
        # ì½ì§€ ì•Šì€ ì¤‘ìš” ë¬¸ì„œë“¤
        unread_critical = self.get_unread_critical_documents(role_id)
        
        for doc in unread_critical:
            gaps.append(f"ë¯¸ì½ìŒ: {doc['title']}")
        
        # ë‚®ì€ ì´í•´ë„ ë¬¸ì„œë“¤
        for access in self.access_logs.values():
            if (access['role_id'] == role_id and 
                access.get('content_read_percentage', 100) < 50):
                gaps.append(f"ë‚®ì€ ì´í•´ë„: {access['document_path']}")
        
        return gaps[:5]  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜

def main():
    """í…ŒìŠ¤íŠ¸ ë° ë°ëª¨"""
    tracker = DocumentTrackingSystem("/home/jungh/workspace/web_community_project")
    
    # ì˜ˆì‹œ: ë¬¸ì„œ ë“±ë¡
    tracker.register_document(
        file_path="roles/business_analyst/deliverables/business_requirements.md",
        role_owner="business_analyst",
        document_type=DocumentType.REQUIREMENT,
        metadata={
            'title': 'Web Community Platform Business Requirements',
            'description': 'ì›¹ ì»¤ë®¤ë‹ˆí‹° í”Œë«í¼ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­',
            'target_readers': ['requirements_analyst', 'system_architect', 'product_owner'],
            'tags': ['requirements', 'business', 'community', 'web'],
            'purpose': 'í”„ë¡œì íŠ¸ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ ì •ì˜ ë° ê³µìœ '
        }
    )
    
    # ì˜ˆì‹œ: ë¬¸ì„œ ì ‘ê·¼ ë¡œê¹…
    tracker.log_document_access(
        document_path="roles/business_analyst/deliverables/business_requirements.md",
        role_id="requirements_analyst",
        access_type=AccessType.READ,
        purpose="ê¸°ìˆ  ìš”êµ¬ì‚¬í•­ ë¶„ì„ì„ ìœ„í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ ê²€í† ",
        duration_seconds=1800,  # 30ë¶„
        content_read_percentage=85.0,
        notes="ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ ì  êµ¬í˜„ ë°©ì•ˆ ê²€í† "
    )
    
    print("âœ… Document Tracking System ë°ëª¨ ì™„ë£Œ")

if __name__ == "__main__":
    main()